from services.llm_explainer import explain_demand_supply

def format_chatbot_response(intent: str, analysis: dict, rag_fallback=None) -> str:
    brain = analysis["brain_decision"]

    if intent == "capacity_decision":
        return f"""
ğŸ“Š NVIDIA GPU Capacity Planning (This Month)

â€¢ Demand Index: {analysis['demand_index']}
â€¢ Supply Capacity: {analysis['supply_capacity']}
â€¢ Backlog Units: {analysis['backlog']}
â€¢ Market Signal: {analysis['live_market_signal']}

ğŸ§  Decision: {brain['decision']}
ğŸ“Œ Reason: {brain['reason']}
âš ï¸ Risk Level: {brain['risk_flag']}
âœ… Confidence: {brain['confidence']}
"""

    if intent == "demand_signal":
        explanation = explain_demand_supply(analysis)
        return f"""
ğŸ“ˆ AI Infrastructure Demand Signal (This Month)

â€¢ Signal: {analysis['live_market_signal']}
â€¢ Explanation: {explanation}
"""

    if intent == "explain_decision":
        explanation = explain_demand_supply(analysis)
        return f"""
ğŸ§  Why This Capacity Decision?

Demand Index: {analysis['demand_index']}
Supply Capacity: {analysis['supply_capacity']}
Backlog: {analysis['backlog']} units
Market Signal: {analysis['live_market_signal']}

Decision: {brain['decision']}
Reason: {brain['reason']}

ğŸ” Detailed Explanation:
{explanation}
"""

    # Knowledge / RAG
    if rag_fallback:
        return rag_fallback

    return "I can analyze NVIDIA GPU capacity, demand signals, or explain planning decisions."
